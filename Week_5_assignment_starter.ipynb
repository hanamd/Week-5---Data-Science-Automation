{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "165166dd",
   "metadata": {},
   "source": [
    "# DS Automation Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c195af74",
   "metadata": {},
   "source": [
    "Using our prepared churn data from week 2:\n",
    "- use pycaret to find an ML algorithm that performs best on the data\n",
    "    - Choose a metric you think is best to use for finding the best model; by default, it is accuracy but it could be AUC, precision, recall, etc. The week 3 FTE has some information on these different metrics.\n",
    "- save the model to disk\n",
    "- create a Python script/file/module with a function that takes a pandas dataframe as an input and returns the probability of churn for each row in the dataframe\n",
    "    - your Python file/function should print out the predictions for new data (new_churn_data.csv)\n",
    "    - the true values for the new data are [1, 0, 0, 1, 0] if you're interested\n",
    "- test your Python module and function with the new data, new_churn_data.csv\n",
    "- write a short summary of the process and results at the end of this notebook\n",
    "- upload this Jupyter Notebook and Python file to a Github repository, and turn in a link to the repository in the week 5 assignment dropbox\n",
    "\n",
    "*Optional* challenges:\n",
    "- return the probability of churn for each new prediction, and the percentile where that prediction is in the distribution of probability predictions from the training dataset (e.g. a high probability of churn like 0.78 might be at the 90th percentile)\n",
    "- use other autoML packages, such as TPOT, H2O, MLBox, etc, and compare performance and features with pycaret\n",
    "- create a class in your Python module to hold the functions that you created\n",
    "- accept user input to specify a file using a tool such as Python's `input()` function, the `click` package for command-line arguments, or a GUI\n",
    "- Use the unmodified churn data (new_unmodified_churn_data.csv) in your Python script. This will require adding the same preprocessing steps from week 2 since this data is like the original unmodified dataset from week 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1602f3",
   "metadata": {},
   "source": [
    "# Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf04d803",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1b00b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('clean_churn_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "006c6fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>customerID</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "      <th>AvgMonthlyCharges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>0</td>\n",
       "      <td>29.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "      <td>0</td>\n",
       "      <td>55.573529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>1</td>\n",
       "      <td>54.075000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>0</td>\n",
       "      <td>40.905556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>1</td>\n",
       "      <td>75.825000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  customerID  tenure  PhoneService  Contract  PaymentMethod  \\\n",
       "0           0  7590-VHVEG       1             0         0              1   \n",
       "1           1  5575-GNVDE      34             1         1              0   \n",
       "2           2  3668-QPYBK       2             1         0              0   \n",
       "3           3  7795-CFOCW      45             0         1              2   \n",
       "4           4  9237-HQITU       2             1         0              1   \n",
       "\n",
       "   MonthlyCharges  TotalCharges  Churn  AvgMonthlyCharges  \n",
       "0           29.85         29.85      0          29.850000  \n",
       "1           56.95       1889.50      0          55.573529  \n",
       "2           53.85        108.15      1          54.075000  \n",
       "3           42.30       1840.75      0          40.905556  \n",
       "4           70.70        151.65      1          75.825000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2f12318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0            0\n",
       "customerID            0\n",
       "tenure                0\n",
       "PhoneService          0\n",
       "Contract              0\n",
       "PaymentMethod         0\n",
       "MonthlyCharges        0\n",
       "TotalCharges          0\n",
       "Churn                 0\n",
       "AvgMonthlyCharges    11\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ab4e4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f227eb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing avgmonthly charge\n",
    "# column as a whole as its not part of the orginal data provided and its similar to monthly charges\n",
    "df.drop(['AvgMonthlyCharges', 'Unnamed: 0','customerID'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70419d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7038</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>84.80</td>\n",
       "      <td>1990.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7039</th>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>103.20</td>\n",
       "      <td>7362.90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7040</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.60</td>\n",
       "      <td>346.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7041</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>74.40</td>\n",
       "      <td>306.60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7042</th>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>105.65</td>\n",
       "      <td>6844.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7043 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      tenure  PhoneService  Contract  PaymentMethod  MonthlyCharges  \\\n",
       "0          1             0         0              1           29.85   \n",
       "1         34             1         1              0           56.95   \n",
       "2          2             1         0              0           53.85   \n",
       "3         45             0         1              2           42.30   \n",
       "4          2             1         0              1           70.70   \n",
       "...      ...           ...       ...            ...             ...   \n",
       "7038      24             1         1              0           84.80   \n",
       "7039      72             1         1              3          103.20   \n",
       "7040      11             0         0              1           29.60   \n",
       "7041       4             1         0              0           74.40   \n",
       "7042      66             1         2              2          105.65   \n",
       "\n",
       "      TotalCharges  Churn  \n",
       "0            29.85      0  \n",
       "1          1889.50      0  \n",
       "2           108.15      1  \n",
       "3          1840.75      0  \n",
       "4           151.65      1  \n",
       "...            ...    ...  \n",
       "7038       1990.50      0  \n",
       "7039       7362.90      0  \n",
       "7040        346.45      0  \n",
       "7041        306.60      1  \n",
       "7042       6844.50      0  \n",
       "\n",
       "[7043 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544b4203",
   "metadata": {},
   "source": [
    "# use pycaret to find an ML algorithm that performs best on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d9e27bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "360c7b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_cd130_row8_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_cd130\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_cd130_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_cd130_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_cd130_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_cd130_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_cd130_row0_col1\" class=\"data row0 col1\" >4843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cd130_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_cd130_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_cd130_row1_col1\" class=\"data row1 col1\" >Churn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cd130_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_cd130_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_cd130_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cd130_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_cd130_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_cd130_row3_col1\" class=\"data row3 col1\" >(7043, 7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cd130_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_cd130_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_cd130_row4_col1\" class=\"data row4 col1\" >(7043, 7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cd130_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_cd130_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_cd130_row5_col1\" class=\"data row5 col1\" >(4930, 7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cd130_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_cd130_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_cd130_row6_col1\" class=\"data row6 col1\" >(2113, 7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cd130_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_cd130_row7_col0\" class=\"data row7 col0\" >Numeric features</td>\n",
       "      <td id=\"T_cd130_row7_col1\" class=\"data row7 col1\" >6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cd130_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_cd130_row8_col0\" class=\"data row8 col0\" >Preprocess</td>\n",
       "      <td id=\"T_cd130_row8_col1\" class=\"data row8 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cd130_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_cd130_row9_col0\" class=\"data row9 col0\" >Imputation type</td>\n",
       "      <td id=\"T_cd130_row9_col1\" class=\"data row9 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cd130_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_cd130_row10_col0\" class=\"data row10 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_cd130_row10_col1\" class=\"data row10 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cd130_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_cd130_row11_col0\" class=\"data row11 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_cd130_row11_col1\" class=\"data row11 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cd130_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_cd130_row12_col0\" class=\"data row12 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_cd130_row12_col1\" class=\"data row12 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cd130_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_cd130_row13_col0\" class=\"data row13 col0\" >Fold Number</td>\n",
       "      <td id=\"T_cd130_row13_col1\" class=\"data row13 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cd130_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_cd130_row14_col0\" class=\"data row14 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_cd130_row14_col1\" class=\"data row14 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cd130_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_cd130_row15_col0\" class=\"data row15 col0\" >Use GPU</td>\n",
       "      <td id=\"T_cd130_row15_col1\" class=\"data row15 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cd130_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_cd130_row16_col0\" class=\"data row16 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_cd130_row16_col1\" class=\"data row16 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cd130_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_cd130_row17_col0\" class=\"data row17 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_cd130_row17_col1\" class=\"data row17 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cd130_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_cd130_row18_col0\" class=\"data row18 col0\" >USI</td>\n",
       "      <td id=\"T_cd130_row18_col1\" class=\"data row18 col1\" >f0b4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x280474a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "automl = setup(df, target = 'Churn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae4b90b",
   "metadata": {},
   "source": [
    "# Choose a metric you think is best to use for finding the best model; by default, it is accuracy but it could be AUC, precision, recall, etc. The week 3 FTE has some information on these different metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a122c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e6787 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_e6787_row0_col0, #T_e6787_row0_col1, #T_e6787_row0_col2, #T_e6787_row0_col4, #T_e6787_row0_col5, #T_e6787_row0_col6, #T_e6787_row0_col7, #T_e6787_row1_col0, #T_e6787_row1_col1, #T_e6787_row1_col2, #T_e6787_row1_col3, #T_e6787_row1_col4, #T_e6787_row2_col0, #T_e6787_row2_col1, #T_e6787_row2_col2, #T_e6787_row2_col3, #T_e6787_row2_col4, #T_e6787_row2_col5, #T_e6787_row2_col6, #T_e6787_row2_col7, #T_e6787_row3_col0, #T_e6787_row3_col1, #T_e6787_row3_col2, #T_e6787_row3_col3, #T_e6787_row3_col4, #T_e6787_row3_col5, #T_e6787_row3_col6, #T_e6787_row3_col7, #T_e6787_row4_col0, #T_e6787_row4_col2, #T_e6787_row4_col3, #T_e6787_row4_col4, #T_e6787_row4_col5, #T_e6787_row4_col6, #T_e6787_row4_col7, #T_e6787_row5_col0, #T_e6787_row5_col1, #T_e6787_row5_col2, #T_e6787_row5_col3, #T_e6787_row5_col4, #T_e6787_row5_col5, #T_e6787_row5_col6, #T_e6787_row5_col7, #T_e6787_row6_col0, #T_e6787_row6_col1, #T_e6787_row6_col2, #T_e6787_row6_col3, #T_e6787_row6_col4, #T_e6787_row6_col5, #T_e6787_row6_col6, #T_e6787_row6_col7, #T_e6787_row7_col0, #T_e6787_row7_col1, #T_e6787_row7_col3, #T_e6787_row7_col4, #T_e6787_row7_col5, #T_e6787_row7_col6, #T_e6787_row7_col7, #T_e6787_row8_col0, #T_e6787_row8_col1, #T_e6787_row8_col2, #T_e6787_row8_col3, #T_e6787_row8_col4, #T_e6787_row8_col5, #T_e6787_row8_col6, #T_e6787_row8_col7, #T_e6787_row9_col0, #T_e6787_row9_col1, #T_e6787_row9_col2, #T_e6787_row9_col3, #T_e6787_row9_col4, #T_e6787_row9_col5, #T_e6787_row9_col6, #T_e6787_row9_col7, #T_e6787_row10_col0, #T_e6787_row10_col1, #T_e6787_row10_col2, #T_e6787_row10_col3, #T_e6787_row10_col4, #T_e6787_row10_col5, #T_e6787_row10_col6, #T_e6787_row10_col7, #T_e6787_row11_col0, #T_e6787_row11_col1, #T_e6787_row11_col2, #T_e6787_row11_col3, #T_e6787_row11_col5, #T_e6787_row11_col6, #T_e6787_row11_col7, #T_e6787_row12_col0, #T_e6787_row12_col1, #T_e6787_row12_col2, #T_e6787_row12_col3, #T_e6787_row12_col4, #T_e6787_row12_col5, #T_e6787_row12_col6, #T_e6787_row12_col7, #T_e6787_row13_col0, #T_e6787_row13_col1, #T_e6787_row13_col2, #T_e6787_row13_col3, #T_e6787_row13_col4, #T_e6787_row13_col5, #T_e6787_row13_col6, #T_e6787_row13_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_e6787_row0_col3, #T_e6787_row1_col5, #T_e6787_row1_col6, #T_e6787_row1_col7, #T_e6787_row4_col1, #T_e6787_row7_col2, #T_e6787_row11_col4 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_e6787_row0_col8, #T_e6787_row2_col8, #T_e6787_row3_col8, #T_e6787_row4_col8, #T_e6787_row5_col8, #T_e6787_row7_col8, #T_e6787_row8_col8, #T_e6787_row9_col8, #T_e6787_row10_col8, #T_e6787_row11_col8, #T_e6787_row12_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_e6787_row1_col8, #T_e6787_row6_col8, #T_e6787_row13_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e6787\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e6787_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_e6787_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_e6787_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_e6787_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_e6787_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_e6787_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_e6787_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_e6787_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_e6787_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e6787_level0_row0\" class=\"row_heading level0 row0\" >nb</th>\n",
       "      <td id=\"T_e6787_row0_col0\" class=\"data row0 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_e6787_row0_col1\" class=\"data row0 col1\" >0.7130</td>\n",
       "      <td id=\"T_e6787_row0_col2\" class=\"data row0 col2\" >0.8044</td>\n",
       "      <td id=\"T_e6787_row0_col3\" class=\"data row0 col3\" >0.7508</td>\n",
       "      <td id=\"T_e6787_row0_col4\" class=\"data row0 col4\" >0.4742</td>\n",
       "      <td id=\"T_e6787_row0_col5\" class=\"data row0 col5\" >0.5813</td>\n",
       "      <td id=\"T_e6787_row0_col6\" class=\"data row0 col6\" >0.3794</td>\n",
       "      <td id=\"T_e6787_row0_col7\" class=\"data row0 col7\" >0.4026</td>\n",
       "      <td id=\"T_e6787_row0_col8\" class=\"data row0 col8\" >0.4550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e6787_level0_row1\" class=\"row_heading level0 row1\" >qda</th>\n",
       "      <td id=\"T_e6787_row1_col0\" class=\"data row1 col0\" >Quadratic Discriminant Analysis</td>\n",
       "      <td id=\"T_e6787_row1_col1\" class=\"data row1 col1\" >0.7529</td>\n",
       "      <td id=\"T_e6787_row1_col2\" class=\"data row1 col2\" >0.8223</td>\n",
       "      <td id=\"T_e6787_row1_col3\" class=\"data row1 col3\" >0.7370</td>\n",
       "      <td id=\"T_e6787_row1_col4\" class=\"data row1 col4\" >0.5245</td>\n",
       "      <td id=\"T_e6787_row1_col5\" class=\"data row1 col5\" >0.6128</td>\n",
       "      <td id=\"T_e6787_row1_col6\" class=\"data row1 col6\" >0.4389</td>\n",
       "      <td id=\"T_e6787_row1_col7\" class=\"data row1 col7\" >0.4526</td>\n",
       "      <td id=\"T_e6787_row1_col8\" class=\"data row1 col8\" >0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e6787_level0_row2\" class=\"row_heading level0 row2\" >svm</th>\n",
       "      <td id=\"T_e6787_row2_col0\" class=\"data row2 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_e6787_row2_col1\" class=\"data row2 col1\" >0.6523</td>\n",
       "      <td id=\"T_e6787_row2_col2\" class=\"data row2 col2\" >0.0000</td>\n",
       "      <td id=\"T_e6787_row2_col3\" class=\"data row2 col3\" >0.6988</td>\n",
       "      <td id=\"T_e6787_row2_col4\" class=\"data row2 col4\" >0.4687</td>\n",
       "      <td id=\"T_e6787_row2_col5\" class=\"data row2 col5\" >0.5154</td>\n",
       "      <td id=\"T_e6787_row2_col6\" class=\"data row2 col6\" >0.2902</td>\n",
       "      <td id=\"T_e6787_row2_col7\" class=\"data row2 col7\" >0.3418</td>\n",
       "      <td id=\"T_e6787_row2_col8\" class=\"data row2 col8\" >0.4650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e6787_level0_row3\" class=\"row_heading level0 row3\" >lightgbm</th>\n",
       "      <td id=\"T_e6787_row3_col0\" class=\"data row3 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_e6787_row3_col1\" class=\"data row3 col1\" >0.7757</td>\n",
       "      <td id=\"T_e6787_row3_col2\" class=\"data row3 col2\" >0.8223</td>\n",
       "      <td id=\"T_e6787_row3_col3\" class=\"data row3 col3\" >0.5145</td>\n",
       "      <td id=\"T_e6787_row3_col4\" class=\"data row3 col4\" >0.5885</td>\n",
       "      <td id=\"T_e6787_row3_col5\" class=\"data row3 col5\" >0.5490</td>\n",
       "      <td id=\"T_e6787_row3_col6\" class=\"data row3 col6\" >0.4006</td>\n",
       "      <td id=\"T_e6787_row3_col7\" class=\"data row3 col7\" >0.4022</td>\n",
       "      <td id=\"T_e6787_row3_col8\" class=\"data row3 col8\" >0.3050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e6787_level0_row4\" class=\"row_heading level0 row4\" >lr</th>\n",
       "      <td id=\"T_e6787_row4_col0\" class=\"data row4 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_e6787_row4_col1\" class=\"data row4 col1\" >0.7921</td>\n",
       "      <td id=\"T_e6787_row4_col2\" class=\"data row4 col2\" >0.8319</td>\n",
       "      <td id=\"T_e6787_row4_col3\" class=\"data row4 col3\" >0.5069</td>\n",
       "      <td id=\"T_e6787_row4_col4\" class=\"data row4 col4\" >0.6359</td>\n",
       "      <td id=\"T_e6787_row4_col5\" class=\"data row4 col5\" >0.5639</td>\n",
       "      <td id=\"T_e6787_row4_col6\" class=\"data row4 col6\" >0.4297</td>\n",
       "      <td id=\"T_e6787_row4_col7\" class=\"data row4 col7\" >0.4346</td>\n",
       "      <td id=\"T_e6787_row4_col8\" class=\"data row4 col8\" >0.6900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e6787_level0_row5\" class=\"row_heading level0 row5\" >dt</th>\n",
       "      <td id=\"T_e6787_row5_col0\" class=\"data row5 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_e6787_row5_col1\" class=\"data row5 col1\" >0.7325</td>\n",
       "      <td id=\"T_e6787_row5_col2\" class=\"data row5 col2\" >0.6614</td>\n",
       "      <td id=\"T_e6787_row5_col3\" class=\"data row5 col3\" >0.5023</td>\n",
       "      <td id=\"T_e6787_row5_col4\" class=\"data row5 col4\" >0.4960</td>\n",
       "      <td id=\"T_e6787_row5_col5\" class=\"data row5 col5\" >0.4991</td>\n",
       "      <td id=\"T_e6787_row5_col6\" class=\"data row5 col6\" >0.3166</td>\n",
       "      <td id=\"T_e6787_row5_col7\" class=\"data row5 col7\" >0.3166</td>\n",
       "      <td id=\"T_e6787_row5_col8\" class=\"data row5 col8\" >0.0150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e6787_level0_row6\" class=\"row_heading level0 row6\" >lda</th>\n",
       "      <td id=\"T_e6787_row6_col0\" class=\"data row6 col0\" >Linear Discriminant Analysis</td>\n",
       "      <td id=\"T_e6787_row6_col1\" class=\"data row6 col1\" >0.7822</td>\n",
       "      <td id=\"T_e6787_row6_col2\" class=\"data row6 col2\" >0.8168</td>\n",
       "      <td id=\"T_e6787_row6_col3\" class=\"data row6 col3\" >0.4809</td>\n",
       "      <td id=\"T_e6787_row6_col4\" class=\"data row6 col4\" >0.6146</td>\n",
       "      <td id=\"T_e6787_row6_col5\" class=\"data row6 col5\" >0.5394</td>\n",
       "      <td id=\"T_e6787_row6_col6\" class=\"data row6 col6\" >0.3995</td>\n",
       "      <td id=\"T_e6787_row6_col7\" class=\"data row6 col7\" >0.4048</td>\n",
       "      <td id=\"T_e6787_row6_col8\" class=\"data row6 col8\" >0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e6787_level0_row7\" class=\"row_heading level0 row7\" >gbc</th>\n",
       "      <td id=\"T_e6787_row7_col0\" class=\"data row7 col0\" >Gradient Boosting Classifier</td>\n",
       "      <td id=\"T_e6787_row7_col1\" class=\"data row7 col1\" >0.7880</td>\n",
       "      <td id=\"T_e6787_row7_col2\" class=\"data row7 col2\" >0.8349</td>\n",
       "      <td id=\"T_e6787_row7_col3\" class=\"data row7 col3\" >0.4794</td>\n",
       "      <td id=\"T_e6787_row7_col4\" class=\"data row7 col4\" >0.6327</td>\n",
       "      <td id=\"T_e6787_row7_col5\" class=\"data row7 col5\" >0.5454</td>\n",
       "      <td id=\"T_e6787_row7_col6\" class=\"data row7 col6\" >0.4106</td>\n",
       "      <td id=\"T_e6787_row7_col7\" class=\"data row7 col7\" >0.4174</td>\n",
       "      <td id=\"T_e6787_row7_col8\" class=\"data row7 col8\" >0.0900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e6787_level0_row8\" class=\"row_heading level0 row8\" >rf</th>\n",
       "      <td id=\"T_e6787_row8_col0\" class=\"data row8 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_e6787_row8_col1\" class=\"data row8 col1\" >0.7677</td>\n",
       "      <td id=\"T_e6787_row8_col2\" class=\"data row8 col2\" >0.8051</td>\n",
       "      <td id=\"T_e6787_row8_col3\" class=\"data row8 col3\" >0.4778</td>\n",
       "      <td id=\"T_e6787_row8_col4\" class=\"data row8 col4\" >0.5747</td>\n",
       "      <td id=\"T_e6787_row8_col5\" class=\"data row8 col5\" >0.5215</td>\n",
       "      <td id=\"T_e6787_row8_col6\" class=\"data row8 col6\" >0.3700</td>\n",
       "      <td id=\"T_e6787_row8_col7\" class=\"data row8 col7\" >0.3729</td>\n",
       "      <td id=\"T_e6787_row8_col8\" class=\"data row8 col8\" >0.0800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e6787_level0_row9\" class=\"row_heading level0 row9\" >et</th>\n",
       "      <td id=\"T_e6787_row9_col0\" class=\"data row9 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_e6787_row9_col1\" class=\"data row9 col1\" >0.7529</td>\n",
       "      <td id=\"T_e6787_row9_col2\" class=\"data row9 col2\" >0.7800</td>\n",
       "      <td id=\"T_e6787_row9_col3\" class=\"data row9 col3\" >0.4725</td>\n",
       "      <td id=\"T_e6787_row9_col4\" class=\"data row9 col4\" >0.5393</td>\n",
       "      <td id=\"T_e6787_row9_col5\" class=\"data row9 col5\" >0.5036</td>\n",
       "      <td id=\"T_e6787_row9_col6\" class=\"data row9 col6\" >0.3401</td>\n",
       "      <td id=\"T_e6787_row9_col7\" class=\"data row9 col7\" >0.3415</td>\n",
       "      <td id=\"T_e6787_row9_col8\" class=\"data row9 col8\" >0.0750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e6787_level0_row10\" class=\"row_heading level0 row10\" >ada</th>\n",
       "      <td id=\"T_e6787_row10_col0\" class=\"data row10 col0\" >Ada Boost Classifier</td>\n",
       "      <td id=\"T_e6787_row10_col1\" class=\"data row10 col1\" >0.7860</td>\n",
       "      <td id=\"T_e6787_row10_col2\" class=\"data row10 col2\" >0.8328</td>\n",
       "      <td id=\"T_e6787_row10_col3\" class=\"data row10 col3\" >0.4702</td>\n",
       "      <td id=\"T_e6787_row10_col4\" class=\"data row10 col4\" >0.6294</td>\n",
       "      <td id=\"T_e6787_row10_col5\" class=\"data row10 col5\" >0.5383</td>\n",
       "      <td id=\"T_e6787_row10_col6\" class=\"data row10 col6\" >0.4028</td>\n",
       "      <td id=\"T_e6787_row10_col7\" class=\"data row10 col7\" >0.4100</td>\n",
       "      <td id=\"T_e6787_row10_col8\" class=\"data row10 col8\" >0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e6787_level0_row11\" class=\"row_heading level0 row11\" >ridge</th>\n",
       "      <td id=\"T_e6787_row11_col0\" class=\"data row11 col0\" >Ridge Classifier</td>\n",
       "      <td id=\"T_e6787_row11_col1\" class=\"data row11 col1\" >0.7899</td>\n",
       "      <td id=\"T_e6787_row11_col2\" class=\"data row11 col2\" >0.0000</td>\n",
       "      <td id=\"T_e6787_row11_col3\" class=\"data row11 col3\" >0.4465</td>\n",
       "      <td id=\"T_e6787_row11_col4\" class=\"data row11 col4\" >0.6527</td>\n",
       "      <td id=\"T_e6787_row11_col5\" class=\"data row11 col5\" >0.5299</td>\n",
       "      <td id=\"T_e6787_row11_col6\" class=\"data row11 col6\" >0.4007</td>\n",
       "      <td id=\"T_e6787_row11_col7\" class=\"data row11 col7\" >0.4129</td>\n",
       "      <td id=\"T_e6787_row11_col8\" class=\"data row11 col8\" >0.4600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e6787_level0_row12\" class=\"row_heading level0 row12\" >knn</th>\n",
       "      <td id=\"T_e6787_row12_col0\" class=\"data row12 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_e6787_row12_col1\" class=\"data row12 col1\" >0.7594</td>\n",
       "      <td id=\"T_e6787_row12_col2\" class=\"data row12 col2\" >0.7361</td>\n",
       "      <td id=\"T_e6787_row12_col3\" class=\"data row12 col3\" >0.4235</td>\n",
       "      <td id=\"T_e6787_row12_col4\" class=\"data row12 col4\" >0.5617</td>\n",
       "      <td id=\"T_e6787_row12_col5\" class=\"data row12 col5\" >0.4829</td>\n",
       "      <td id=\"T_e6787_row12_col6\" class=\"data row12 col6\" >0.3302</td>\n",
       "      <td id=\"T_e6787_row12_col7\" class=\"data row12 col7\" >0.3358</td>\n",
       "      <td id=\"T_e6787_row12_col8\" class=\"data row12 col8\" >0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e6787_level0_row13\" class=\"row_heading level0 row13\" >dummy</th>\n",
       "      <td id=\"T_e6787_row13_col0\" class=\"data row13 col0\" >Dummy Classifier</td>\n",
       "      <td id=\"T_e6787_row13_col1\" class=\"data row13 col1\" >0.7347</td>\n",
       "      <td id=\"T_e6787_row13_col2\" class=\"data row13 col2\" >0.5000</td>\n",
       "      <td id=\"T_e6787_row13_col3\" class=\"data row13 col3\" >0.0000</td>\n",
       "      <td id=\"T_e6787_row13_col4\" class=\"data row13 col4\" >0.0000</td>\n",
       "      <td id=\"T_e6787_row13_col5\" class=\"data row13 col5\" >0.0000</td>\n",
       "      <td id=\"T_e6787_row13_col6\" class=\"data row13 col6\" >0.0000</td>\n",
       "      <td id=\"T_e6787_row13_col7\" class=\"data row13 col7\" >0.0000</td>\n",
       "      <td id=\"T_e6787_row13_col8\" class=\"data row13 col8\" >0.0100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2812ff350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model = compare_models( fold = 2, sort = 'Recall')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d18cd3",
   "metadata": {},
   "source": [
    "# save the model to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ab2c817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Saved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Pipeline(memory=Memory(location=None),\n",
       "          steps=[('numerical_imputer',\n",
       "                  TransformerWrapper(exclude=None,\n",
       "                                     include=['tenure', 'PhoneService',\n",
       "                                              'Contract', 'PaymentMethod',\n",
       "                                              'MonthlyCharges', 'TotalCharges'],\n",
       "                                     transformer=SimpleImputer(add_indicator=False,\n",
       "                                                               copy=True,\n",
       "                                                               fill_value=None,\n",
       "                                                               missing_values=nan,\n",
       "                                                               strategy='mean',\n",
       "                                                               verbose='deprecated'))),\n",
       "                 ('categorical_imputer',\n",
       "                  TransformerWrapper(exclude=None, include=[],\n",
       "                                     transformer=SimpleImputer(add_indicator=False,\n",
       "                                                               copy=True,\n",
       "                                                               fill_value=None,\n",
       "                                                               missing_values=nan,\n",
       "                                                               strategy='most_frequent',\n",
       "                                                               verbose='deprecated'))),\n",
       "                 ('trained_model',\n",
       "                  GaussianNB(priors=None, var_smoothing=1e-09))],\n",
       "          verbose=False),\n",
       " 'best_model_recall.pkl')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_model(best_model, 'best_model_recall')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c44b34",
   "metadata": {},
   "source": [
    "# create a Python script/file/module with a function that takes a pandas dataframe as an input and returns the probability of churn for each row in the dataframe\n",
    "## your Python file/function should print out the predictions for new data (new_churn_data.csv)\n",
    "## the true values for the new data are [1, 0, 0, 1, 0] if you're interested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c1aec53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Loaded\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   customerID  tenure  PhoneService  Contract  PaymentMethod  MonthlyCharges  \\\n",
      "0  9305-CKSKC      22             1         0              2       97.400002   \n",
      "1  1452-KNGVK       8             0         1              1       77.300003   \n",
      "2  6723-OKKJM      28             1         0              0       28.250000   \n",
      "3  7832-POPKP      62             1         0              2      101.699997   \n",
      "4  6348-TACGU      10             0         0              1       51.150002   \n",
      "\n",
      "   TotalCharges  charge_per_tenure  prediction_label  prediction_score  \n",
      "0    811.700012          36.895454                 1            0.8036  \n",
      "1   1701.949951         212.743744                 0            0.7563  \n",
      "2    250.899994           8.960714                 0            0.5168  \n",
      "3   3106.560059          50.105808                 0            0.7582  \n",
      "4   3440.969971         344.096985                 1            0.5606  \n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "def prob_churn(data):\n",
    "    \n",
    "    with open ('best_model_recall.pk','rb') as f:\n",
    "            loaded_model = pickle.load(f)\n",
    "    \n",
    "    loaded_lda = load_model('best_model_recall')\n",
    "    \n",
    "    \n",
    "    prediction = predict_model(loaded_lda, data)\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "data = pd.read_csv('new_churn_data.csv')\n",
    "\n",
    "output = prob_churn(data)\n",
    "#output_with_id = pd.concat([df_copy['customerID'], output], axis=1)\n",
    "\n",
    "print(output)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42468945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True values for new data:\n",
      "0    1\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    1\n",
      "Name: prediction_label, dtype: int64\n",
      "\n",
      " Expected True values for new data:\n",
      "\n",
      "  [1, 0, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"True values for new data:\")\n",
    "print(output['prediction_label'] )\n",
    "\n",
    "print(\"\\n Expected True values for new data:\")\n",
    "true_values = [1, 0, 0, 1, 0]\n",
    "print(\"\\n \",true_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49db562",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf625e0",
   "metadata": {},
   "source": [
    "For this assignment, I started by loading my data and checking for any missing values in case I missed any from the week 2 assignment file. It seemed that I had some missing files, so I decided to drop the column \"AvgMonthlyCharges\" as it had missing values as well as having similar content as the \"MonthlyCharges\" column. After completing that step, I went on to drop additional columns like \"uname: 0\" as it wasn't needed, as well as \"CustomerID\" as sometimes it causes issues in my code when wanting to only deal with integer values but the customer ID contains both character and integer values.\n",
    "\n",
    "After having a clean dataset, I went on to use PyCaret's AutoML to run my machine learning algorithm. Using the setup function, I specified my data and my target variable which was \"Churn.\" Afterwards, I ran a compare model test with the metric set as recall because recall is the best model when looking at churn because it can best prioritize the identification of churn cases, aiming to minimize false negatives and capture as many actual churners as possible.\n",
    "\n",
    "Once completing that step, I went on to save my model to disk for later use. In the end, to use it on new data, I retrieved it in my function called \"prob_churn\" using the open statement as a readable file only. Once it did that, I loaded the model to be used using the \"load_model\" function. Afterward, in my function, I was able to use the \"predict_model\" function to use my loaded model to predict the outcome of the new given data.\n",
    "\n",
    "You can see from the result of using \"new_churn_data.csv\" as my data, I get a true value of 10001 instead of the proposed true value of 10001. My guess for the reason being is that \"fold = 5\" might be affecting the true positive, but I did try changing it and still got an outcome of 10101 instead using \"fold = 20.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9533a1cd",
   "metadata": {},
   "source": [
    "Write a short summary of the process and results here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
